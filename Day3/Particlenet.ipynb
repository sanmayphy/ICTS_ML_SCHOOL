{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 2.0.1\n",
      "PyG version 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import ortho_group\n",
    "\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "from typing import Callable, Union\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, ReLU, BatchNorm1d, Module, Sequential\n",
    "from torch import Tensor\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "from torch_geometric.typing import (\n",
    "    Adj,\n",
    "    OptPairTensor,\n",
    "    OptTensor,\n",
    "    Size,\n",
    "    SparseTensor,\n",
    "    torch_sparse,\n",
    "    PairTensor\n",
    ")\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import Batch\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import remove_self_loops, to_dense_adj, dense_to_sparse, to_undirected\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool, knn_graph\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_scatter import scatter\n",
    "from torch_cluster import knn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import uproot\n",
    "import vector\n",
    "vector.register_awkward()\n",
    "import awkward as ak\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "print(\"PyTorch version {}\".format(torch.__version__))\n",
    "print(\"PyG version {}\".format(torch_geometric.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Jet_Dataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, dataset_path:str, tree_name:str = 'tree', k:int = 5) -> None:\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            size - Number of data points we want to generate\n",
    "            std - Standard deviation of the noise (see generate_continuous_xor function)\n",
    "        \"\"\"\n",
    "        super(Jet_Dataset, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.dataset = uproot.open(dataset_path)\n",
    "        self.tree = self.dataset[tree_name].arrays()\n",
    "        \n",
    "        self.num_entries = self.dataset[tree_name].num_entries\n",
    "        \n",
    "        self.part_feat = self.dataset[tree_name].keys(filter_name='part_*')\n",
    "        self.jet_feat = self.dataset[tree_name].keys(filter_name='jet_*')\n",
    "        self.labels = self.dataset[tree_name].keys(filter_name='labels_*')\n",
    "        \n",
    "        self.k = k\n",
    "        \n",
    "        \n",
    "        #self.pc_dataset = [ self.transform_jet_to_point_cloud(idx) for idx in range(self.num_entries-1) ]\n",
    "        \n",
    "\n",
    "    def transform_jet_to_point_cloud(self, idx:int) -> Data :\n",
    "    \n",
    "        npart = self.tree['jet_nparticles'].to_numpy()[idx:idx+1]\n",
    "        \n",
    "        part_feat_list = [ak.flatten(self.tree[part_feat][idx:idx+1]).to_numpy() for part_feat in self.part_feat]\n",
    "        \n",
    "        jet_pt = self.tree['jet_pt'].to_numpy()[idx:idx+1]\n",
    "        jet_eta = self.tree['jet_eta'].to_numpy()[idx:idx+1]\n",
    "        jet_phi = self.tree['jet_phi'].to_numpy()[idx:idx+1]\n",
    "        jet_energy = self.tree['jet_energy'].to_numpy()[idx:idx+1]\n",
    "        jet_tau21 = self.tree['jet_tau2'].to_numpy()[idx:idx+1]/self.tree['jet_tau1'].to_numpy()[idx:idx+1]\n",
    "        jet_tau32 = self.tree['jet_tau3'].to_numpy()[idx:idx+1]/self.tree['jet_tau2'].to_numpy()[idx:idx+1]\n",
    "        jet_tau43 = self.tree['jet_tau4'].to_numpy()[idx:idx+1]/self.tree['jet_tau3'].to_numpy()[idx:idx+1]\n",
    "        \n",
    "        \n",
    "        jet_sd_mass = self.tree['jet_sdmass'].to_numpy()[idx:idx+1]\n",
    "        \n",
    "        jet_feat = np.stack([jet_pt, jet_eta, jet_phi, jet_energy, jet_tau21, jet_tau32, jet_tau43]).T\n",
    "              \n",
    "        #jet_feat = np.repeat(jet_feat, int(npart), axis=0)\n",
    "             \n",
    "        part_feat = np.stack(part_feat_list).T\n",
    "        \n",
    "        total_jet_feat = part_feat #np.concatenate((part_feat, jet_feat), axis=-1)\n",
    "        total_jet_feat[np.isnan(total_jet_feat)] = 0.\n",
    "        \n",
    "        #print(type(total_jet_feat), 'total_jet_feat shape : ', total_jet_feat.shape)\n",
    "        \n",
    "        jet_class = -1\n",
    "        \n",
    "        if(self.tree['label_QCD'].to_numpy()[idx:idx+1] == 1) : jet_class = 0\n",
    "        \n",
    "        if( (self.tree['label_Tbqq'].to_numpy()[idx:idx+1] == 1) or\n",
    "            (self.tree['label_Tbl'].to_numpy()[idx:idx+1] == 1)) : jet_class = 2\n",
    "        \n",
    "        if( (self.tree['label_Zqq'].to_numpy()[idx:idx+1] == 1) or\n",
    "            (self.tree['label_Wqq'].to_numpy()[idx:idx+1] == 1)) : jet_class = 0\n",
    "        \n",
    "        if( (self.tree['label_Hbb'].to_numpy()[idx:idx+1] == True) or\n",
    "            (self.tree['label_Hcc'].to_numpy()[idx:idx+1] == True) or\n",
    "            (self.tree['label_Hgg'].to_numpy()[idx:idx+1] == True) or\n",
    "            (self.tree['label_H4q'].to_numpy()[idx:idx+1] == True) or\n",
    "            (self.tree['label_Hqql'].to_numpy()[idx:idx+1] == True) ) : jet_class = 1\n",
    "        \n",
    "        part_eta = torch.tensor( ak.flatten(self.tree['part_deta'][idx:idx+1]).to_numpy() )\n",
    "        part_phi = torch.tensor( ak.flatten(self.tree['part_dphi'][idx:idx+1]).to_numpy() )\n",
    "        eta_phi_pos = torch.stack([part_eta, part_phi], dim=-1)\n",
    "        \n",
    "        edge_index = torch_geometric.nn.pool.knn_graph(x = eta_phi_pos, k = self.k)\n",
    "        \n",
    "        src, dst = edge_index\n",
    "                \n",
    "        part_del_eta = part_eta[dst] - part_eta[src]\n",
    "        part_del_phi = part_phi[dst] - part_phi[src]\n",
    "        \n",
    "        part_del_R = torch.hypot(part_del_eta, part_del_phi).view(-1, 1) # -- why do we need this view function ? \n",
    "        \n",
    "        data = Data(x=torch.tensor(total_jet_feat), edge_index=edge_index, edge_deltaR = part_del_R)\n",
    "        data.label = torch.tensor([jet_class])\n",
    "        data.sd_mass = torch.tensor(jet_sd_mass)\n",
    "        data.global_data = torch.tensor(jet_feat)\n",
    "        data.seq_length = torch.tensor(npart)\n",
    "        \n",
    "        return data    \n",
    "        \n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        # Number of data point we have. Alternatively self.data.shape[0], or self.label.shape[0]\n",
    "        return self.num_entries#len(self.pc_dataset)\n",
    "    \n",
    "    def __getitem__(self, idx:int) -> Data :\n",
    "        # Return the idx-th data point of the dataset\n",
    "    \n",
    "        return self.transform_jet_to_point_cloud(idx)#self.pc_dataset[idx]#data_point, data_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(in_size, layer_size, depth):\n",
    "    layers = []\n",
    "\n",
    "    layers.append(nn.Linear(in_size * 2, layer_size))\n",
    "    layers.append(nn.BatchNorm1d(layer_size))\n",
    "    layers.append(nn.ReLU())\n",
    "\n",
    "    for i in range(depth):\n",
    "        layers.append(nn.Linear(layer_size, layer_size))\n",
    "        layers.append(nn.BatchNorm1d(layer_size))\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is an edge convolution?\n",
    "If the message function $m_{ij} = h_{\\bf \\Theta}(x_i, x_j)$, it is called **Edgeconvolution**. \n",
    "<img src=\"edgeconv_cartoon.png\" alt=\"Alternative text\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DGCNN paper (https://arxiv.org/pdf/1801.07829.pdf) proposed $m_{ij} = \\sigma \\Big( \\theta_{m}(x_j - x_i) + \\phi_m x_i\\Big)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(EdgeConv, self).__init__(aggr='mean') #  \"Mean\" aggregation.\n",
    "        \n",
    "        self.theta = Sequential(Linear(in_channels, out_channels),\n",
    "                       ReLU(),\n",
    "                       Linear(out_channels, out_channels))\n",
    "        \n",
    "        self.phi = Sequential(Linear(in_channels, out_channels),\n",
    "                       ReLU(),\n",
    "                       Linear(out_channels, out_channels))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        return self.propagate(edge_index, x=x)\n",
    "\n",
    "    def message(self, x_i, x_j):\n",
    "        # x_i has shape [E, in_channels]\n",
    "        # x_j has shape [E, in_channels]\n",
    "        \n",
    "        out = self.theta(x_j - x_i) + self.phi(x_i)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center width=\"500%\"><img src=\"edgeconv_cartoon.png\" width=\"600px\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For DynamicEdgeConv, the adjacency is determined on fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicEdgeConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, k):\n",
    "        super(DynamicEdgeConv, self).__init__(aggr='mean') #  \"Mean\" aggregation.\n",
    "        \n",
    "        self.k = k\n",
    "        \n",
    "        self.theta = Sequential(Linear(in_channels, out_channels),\n",
    "                       ReLU(),\n",
    "                       Linear(out_channels, out_channels))\n",
    "        \n",
    "        self.phi = Sequential(Linear(in_channels, out_channels),\n",
    "                       ReLU(),\n",
    "                       Linear(out_channels, out_channels))\n",
    "\n",
    "    def forward(self, x, batch=None):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "        edge_index = knn_graph(x, self.k, batch, loop=False, flow=self.flow)\n",
    "        return self.propagate(edge_index=edge_index, x=x)\n",
    "\n",
    "    def message(self, x_i, x_j):\n",
    "        # x_i has shape [E, in_channels]\n",
    "        # x_j has shape [E, in_channels]\n",
    "        \n",
    "        out = self.theta(x_j - x_i) + self.phi(x_i)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The CMS model \n",
    "https://cms-ml.github.io/documentation/inference/particlenet.html\n",
    "<center width=\"700%\"><img src=\"particlenet_full_arch.png\" width=\"800px\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference : https://github.com/farakiko/xai4hep/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeConv_lrp(MessagePassing):\n",
    "    \"\"\"\n",
    "    Copied from pytorch_geometric source code, with the following edits\n",
    "    1. torch.cat([x_i, x_j - x_i], dim=-1)) -> torch.cat([x_i, x_j], dim=-1))\n",
    "    2. retrieve edge_activations\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nn: Callable, aggr: str = \"max\", **kwargs):\n",
    "        super().__init__(aggr=aggr, **kwargs)\n",
    "        self.nn = nn\n",
    "\n",
    "    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj) -> Tensor:\n",
    "        if isinstance(x, Tensor):\n",
    "            x: PairTensor = (x, x)\n",
    "        # propagate_type: (x: PairTensor)\n",
    "        return (\n",
    "            self.propagate(edge_index, x=x, size=None),\n",
    "            self.edge_activations,\n",
    "        )\n",
    "\n",
    "    def message(self, x_i: Tensor, x_j: Tensor) -> Tensor:\n",
    "        # self.edge_activations = self.nn(torch.cat([x_i, x_j - x_i], dim=-1))\n",
    "        # return self.nn(torch.cat([x_i, x_j - x_i], dim=-1))\n",
    "        self.edge_activations = self.nn(torch.cat([x_i, x_j], dim=-1))\n",
    "        return self.nn(torch.cat([x_i, x_j], dim=-1))\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}(nn={self.nn})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeConvBlock(nn.Module):\n",
    "    def __init__(self, in_size, layer_size, depth):\n",
    "        super(EdgeConvBlock, self).__init__()\n",
    "        \n",
    "        edge_mlp = build_mlp(in_size=in_size, layer_size=layer_size, depth=depth)\n",
    "        self.edge_conv = EdgeConv_lrp(edge_mlp, aggr=\"mean\")\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        return self.edge_conv(x, edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticleNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        for_LRP,\n",
    "        node_feat_size,\n",
    "        num_classes=1,\n",
    "        k=16,\n",
    "        depth=2,\n",
    "        dropout=False,\n",
    "        ):\n",
    "        super(ParticleNet, self).__init__()\n",
    "        self.for_LRP = for_LRP\n",
    "\n",
    "        self.node_feat_size = node_feat_size\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.k = k\n",
    "        self.num_edge_conv_blocks = 3\n",
    "\n",
    "        self.kernel_sizes = [self.node_feat_size, 64, 128, 256]\n",
    "        self.input_sizes = np.cumsum(self.kernel_sizes)  # [4, 4+64, 4+64+128, 4+64+128+256]\n",
    "\n",
    "        self.fc_size = 256\n",
    "\n",
    "        if dropout:\n",
    "            self.dropout = 0.1\n",
    "            self.dropout_layer = nn.Dropout(p=self.dropout)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "\n",
    "        # define the edgeconvblocks\n",
    "        self.edge_conv_blocks = nn.ModuleList()\n",
    "        for i in range(0, self.num_edge_conv_blocks):\n",
    "            self.edge_conv_blocks.append(EdgeConvBlock(self.input_sizes[i], self.kernel_sizes[i + 1], depth=depth))\n",
    "\n",
    "        # define the fully connected networks (post-edgeconvs)\n",
    "        self.fc1 = nn.Linear(self.input_sizes[-1], self.fc_size)\n",
    "        self.fc2 = nn.Linear(self.fc_size, self.num_classes)\n",
    "\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x = batch.x\n",
    "        y = batch.label\n",
    "        batch = batch.batch\n",
    "\n",
    "        # input transformations\n",
    "        # x[:, 2] = (x[:, 2] - 1.7) * 0.7  # part_pt_log\n",
    "        # x[:, 3] = (x[:, 3] - 2.0) * 0.7  # part_e_log\n",
    "        # x[:, 4] = (x[:, 4] + 4.7) * 0.7  # part_logptrel\n",
    "        # x[:, 5] = (x[:, 5] + 4.7) * 0.7  # part_logerel\n",
    "        # x[:, 6] = (x[:, 6] - 0.2) * 4.7  # part_deltaR\n",
    "\n",
    "        # useful placeholders for LRP studies\n",
    "        edge_activations = {}\n",
    "        edge_block_activations = {}\n",
    "        edge_index = {}\n",
    "\n",
    "        for i in range(self.num_edge_conv_blocks):\n",
    "            # using only angular coords for knn in first edgeconv block\n",
    "            edge_index[f\"edge_conv_{i}\"] = knn_graph(x[:, :2], self.k, batch) if i == 0 else knn_graph(x, self.k, batch)\n",
    "\n",
    "            out, edge_activations[f\"edge_conv_{i}\"] = self.edge_conv_blocks[i](x, edge_index[f\"edge_conv_{i}\"])\n",
    "\n",
    "            x = torch.cat((out, x), dim=1)  # concatenating with latent features i.e. skip connections per EdgeConvBlock\n",
    "\n",
    "            edge_block_activations[f\"edge_conv_{i}\"] = x\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        if self.dropout:\n",
    "            x = self.dropout_layer(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sig(x)\n",
    "\n",
    "        # save different objects if you are running lrp studies\n",
    "        if self.for_LRP:\n",
    "            return x, edge_activations, edge_block_activations, edge_index\n",
    "        else:\n",
    "            return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's make the dataset and try the forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/Users/sanmay/Documents/ICTS_SCHOOL/Main_School/JetDataset/'\n",
    "file_name = dataset_path + 'JetClass_example_100k.root' # -- from -- \"https://hqu.web.cern.ch/datasets/JetClass/example/\" #\n",
    "jet_dataset = Jet_Dataset(dataset_path=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset=jet_dataset, batch_size=5, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_b = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[204, 16], edge_index=[2, 1020], edge_deltaR=[1020, 1], label=[5], sd_mass=[5], global_data=[5, 7], seq_length=[5], batch=[204], ptr=[6])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = {\n",
    "        \"for_LRP\": True,\n",
    "        \"node_feat_size\": 16,\n",
    "        \"num_classes\": 3,\n",
    "        \"k\": 5,\n",
    "        \"depth\": 3,\n",
    "        \"dropout\": True,\n",
    "    }\n",
    "\n",
    "model = ParticleNet(**model_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, edge_activations, edge_block_activations, edge_index = model(gr_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4062, 0.5569, 0.5802],\n",
      "        [0.4900, 0.4941, 0.5671],\n",
      "        [0.4520, 0.5209, 0.5346],\n",
      "        [0.4598, 0.4562, 0.4763],\n",
      "        [0.4757, 0.5539, 0.5282]], grad_fn=<SigmoidBackward0>) {'edge_conv_0': tensor([[0.0000, 0.0000, 0.0000,  ..., 2.4165, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 2.5682, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.1482, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.1642, 0.5683, 0.1173,  ..., 0.3045, 0.5227, 0.0000],\n",
      "        [0.2873, 0.4984, 0.1636,  ..., 0.1613, 0.4388, 0.0000],\n",
      "        [0.3443, 0.4965, 0.1143,  ..., 0.2033, 0.4958, 0.0297]],\n",
      "       grad_fn=<ReluBackward0>), 'edge_conv_1': tensor([[1.5739, 2.4793, 0.0000,  ..., 4.9247, 5.2629, 2.0914],\n",
      "        [2.3610, 3.8313, 0.0000,  ..., 3.8476, 4.9276, 1.7503],\n",
      "        [1.9533, 3.8250, 0.1490,  ..., 3.8515, 4.8008, 1.6695],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.2437,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2225,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.3306,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>), 'edge_conv_2': tensor([[1.9983, 1.2999, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0554, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0376, 0.0000,  ..., 0.0660, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.1578, 0.0000, 0.1383,  ..., 0.2076, 0.0446, 0.0000],\n",
      "        [0.1452, 0.0000, 0.1276,  ..., 0.1908, 0.0147, 0.0000],\n",
      "        [0.2149, 0.0000, 0.0254,  ..., 0.1094, 0.0466, 0.0220]],\n",
      "       grad_fn=<ReluBackward0>)} {'edge_conv_0': tensor([[0.0000, 0.0000, 0.1314,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.3057,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.3399, 0.5338, 0.0245,  ..., 0.0000, 1.0000, 0.0000],\n",
      "        [0.3146, 0.4981, 0.0788,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.2960, 0.5014, 0.1060,  ..., 1.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CatBackward0>), 'edge_conv_1': tensor([[1.2426, 4.1291, 0.8121,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.6395, 3.4542, 0.3369,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.1177, 2.1157, 0.4635,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.3770,  ..., 0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2509,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2602,  ..., 1.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CatBackward0>), 'edge_conv_2': tensor([[0.3997, 1.2224, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.0447, 1.0796, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.5768, 1.1386, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.2174, 0.0000, 0.1441,  ..., 0.0000, 1.0000, 0.0000],\n",
      "        [0.1786, 0.0000, 0.1217,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.1919, 0.0000, 0.0866,  ..., 1.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CatBackward0>)} {'edge_conv_0': tensor([[  2,   3,   1,  ..., 199, 200, 197],\n",
      "        [  0,   0,   0,  ..., 203, 203, 203]]), 'edge_conv_1': tensor([[  1,   2,   3,  ..., 200, 195, 201],\n",
      "        [  0,   0,   0,  ..., 203, 203, 203]]), 'edge_conv_2': tensor([[  1,   2,   3,  ..., 197, 195, 198],\n",
      "        [  0,   0,   0,  ..., 203, 203, 203]])}\n"
     ]
    }
   ],
   "source": [
    "print(x, edge_activations, edge_block_activations, edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW try to visualize the adjacency after each layer of EdgeConv. Please do a training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
